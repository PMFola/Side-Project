# Side-Project
Independent portfolio project inspired by my MSc work and real challenges faced during my role at Flatiron Health.
# AI Ethics Audit Toolkit for Clinical Decision Support Systems

👩🏽‍⚕️ Created by: Folasade Akinyemi  
🎯 Role: Product Manager & Clinical Governance Strategist  
🗓️ Timeline: June 2025 (Concept Project)

---

## 🧠 Overview

This toolkit was born out of my work in AI-powered oncology tools and my current advent into Masters in Human-Centred Artificial Intelligence. As both a clinical specialist and product strategist, I wanted to create a lightweight, actionable framework to help product teams, clinicians, and compliance leads evaluate the ethical maturity of AI-driven clinical decision support systems (CDS).

Think of it as a compass that is helping teams navigate trust, bias, explainability, and safety in real-world ML tools.

---

## 🔍 Why This Matters

Too often, AI in healthcare is technically brilliant but ethically shaky. As someone who has worked in oncology and now helps design AI-powered workflows, I’ve seen where trust gaps emerge:

* Outputs that aren’t explainable to clinicians
* Bias in training data, missed in performance metrics
* Poor documentation or clinical transparency
* Lack of human-in-the-loop feedback mechanisms

This toolkit offers a structured way to assess these risks before deployment, or ideally, from the design phase.


## 🧰 What’s Included

### ✅ Ethics Audit Checklist (MVP)
* Structured around five pillars:
* Explainability & Transparency
* Bias & Fairness
* Clinical Safety
* User Trust
* Regulatory Readiness

### 📄 Stakeholder Review Template
For collaborative evaluations across PMs, clinicians, and governance leads.

### 🧪 AI Model Factsheet Generator
Inspired by “Model Cards”, helps document model intent, limitations, performance, and fairness.

### ✍🏾 Ethical Design Brief Prompts
Supports teams during discovery to capture early assumptions and ethical intent.

---

## 💡 My Role

I designed and authored this toolkit as a standalone portfolio project, building on:
* MSc work in ethical AI and explainability
* My day-to-day role at Flatiron Health
* Hands-on experience rolling out ML-enabled workflows and seeing user trust challenges up close


## 🛠 Tools & Methods
 **Research & Benchmarking**: NHS AI Lab, ICO Auditing, ISO 14971
 **Design**: Miro (Stakeholder maps), Figma (UX audit flows)
 **Docs & Sharing**: Notion, Google Docs, Markdown


## 🙋🏽‍♀️ Let’s Collaborate
If you're building an AI tool in healthcare and want to embed trust from the start, let’s talk! This toolkit is a starting point, and I’m always happy to co-develop or adapt it to real product settings.
